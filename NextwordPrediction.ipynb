{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextwordPrediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU4Deu7MV9rm"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci8GpQ5cWV-B"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YtQLKu0GWfgu",
        "outputId": "11b58813-c5da-43d4-e3a1-d3bd344af4ce"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22002bd5-6b0d-4390-b056-f531554c4f09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22002bd5-6b0d-4390-b056-f531554c4f09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ip for rnn.txt to ip for rnn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_P_DEe3X_El"
      },
      "source": [
        "# Loading and Pre-Processing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "P9Pef4Q8YEq4",
        "outputId": "44ed9521-39ca-4e40-a8c4-9142ecadda3a"
      },
      "source": [
        "# Now, Let's Load the data.\n",
        "file = open(\"ip for rnn.txt\", \"r\", encoding = \"utf8\")\n",
        "# we opened the file in reading mode.\n",
        "\n",
        "#Let's Pre-Process the data.\n",
        "#Pre-Processng methods depends on our data.\n",
        "\n",
        "# store file in list\n",
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "\n",
        "# Convert list to string\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '. join(lines)\n",
        "\n",
        "#Depending on our data these steps are needed to mae our data suitable for processing.\n",
        "#replace unnecessary stuff with space\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
        "\n",
        "#remove unnecessary spaces \n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Project Gutenberg eBook of Pride and Prejudice, by Jane Austen This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF35-UhEZq9m",
        "outputId": "2170454e-80b3-4bdb-d97c-e9c64032113d"
      },
      "source": [
        "len(data)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "698483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS-JfXxzZuLv"
      },
      "source": [
        "# Tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnInB4OHZt1R",
        "outputId": "ed12aabe-6a71-40b5-c1a6-aa34be07948f"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 176, 157, 916, 3, 321, 4, 1174, 30, 72, 2535, 41, 916, 23, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-qcqGMtZ-AQ",
        "outputId": "9e2283c9-98d4-4c83-e693-b91efa6df25c"
      },
      "source": [
        "len(sequence_data)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAb0NkBaaAyg",
        "outputId": "b95be022-9447-47a2-a7da-79387f982a9e"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFtcUjmmai-G"
      },
      "source": [
        "Here we are using 3 words to predict the 4th word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eq9UPsHa-CS",
        "outputId": "ebe8cda3-4df0-4da4-ccb6-ea983ad29319"
      },
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "    \n",
        "print(\"The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Length of sequences are:  125314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  176,  157,  916],\n",
              "       [ 176,  157,  916,    3],\n",
              "       [ 157,  916,    3,  321],\n",
              "       [ 916,    3,  321,    4],\n",
              "       [   3,  321,    4, 1174],\n",
              "       [ 321,    4, 1174,   30],\n",
              "       [   4, 1174,   30,   72],\n",
              "       [1174,   30,   72, 2535],\n",
              "       [  30,   72, 2535,   41],\n",
              "       [  72, 2535,   41,  916]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LhT_5-TbGew"
      },
      "source": [
        "Above array each element has 4 elements the first 3 are the input and the last word is the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FICMFxAObFx-"
      },
      "source": [
        "# Now as we got to kow what are the i/p and o/p are so let's separate them.\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "    \n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyB5O09qaPV-",
        "outputId": "796a63db-31a3-407c-f33a-447344ba47f5"
      },
      "source": [
        "print(\"Input Data: \", X[:10])\n",
        "print(\"Output Response: \", y[:10])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Data:  [[   1  176  157]\n",
            " [ 176  157  916]\n",
            " [ 157  916    3]\n",
            " [ 916    3  321]\n",
            " [   3  321    4]\n",
            " [ 321    4 1174]\n",
            " [   4 1174   30]\n",
            " [1174   30   72]\n",
            " [  30   72 2535]\n",
            " [  72 2535   41]]\n",
            "Output Response:  [ 916    3  321    4 1174   30   72 2535   41  916]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMT1iAnPdU_h",
        "outputId": "04fb466d-244d-40fb-d24b-5338bbd7e3d2"
      },
      "source": [
        "#Now we will be converting our Class Vectors into some binary Class Matrix Later we will be using Loss function as Categorical Loss entropy. This requires our Interger values to be in Binary Matrice.\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnWJxrRed7zT"
      },
      "source": [
        "# Now Let's Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJvBdpCd_4f"
      },
      "source": [
        "#we will be using Sequential for our model RNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "#input_length means we will be using 3 words to predict next word.\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "#Two LSTM layers are there\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB8Q5YEwezLQ",
        "outputId": "462415ad-ea6e-4fd9-d547-2892d337b1d2"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3, 10)             70360     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 3, 1000)           4044000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7036)              7043036   \n",
            "=================================================================\n",
            "Total params: 20,162,396\n",
            "Trainable params: 20,162,396\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Omw04be5A4"
      },
      "source": [
        "# Ploting Our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "m8PJJ7JDe8EP",
        "outputId": "25df329b-add7-4926-d884-107b911a7893"
      },
      "source": [
        "#Just Take a look at Our Model\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vew3sag4fGt9"
      },
      "source": [
        "# Building Our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpvIhyhifMmo",
        "outputId": "d64a6cdd-8698-4d98-ca94-b75cadbad76b"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "1959/1959 [==============================] - 38s 15ms/step - loss: 6.2294\n",
            "\n",
            "Epoch 00001: loss improved from inf to 6.22942, saving model to next_words.h5\n",
            "Epoch 2/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 5.5943\n",
            "\n",
            "Epoch 00002: loss improved from 6.22942 to 5.59425, saving model to next_words.h5\n",
            "Epoch 3/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 5.2643\n",
            "\n",
            "Epoch 00003: loss improved from 5.59425 to 5.26425, saving model to next_words.h5\n",
            "Epoch 4/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 5.0368\n",
            "\n",
            "Epoch 00004: loss improved from 5.26425 to 5.03678, saving model to next_words.h5\n",
            "Epoch 5/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 4.8360\n",
            "\n",
            "Epoch 00005: loss improved from 5.03678 to 4.83603, saving model to next_words.h5\n",
            "Epoch 6/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 4.6383\n",
            "\n",
            "Epoch 00006: loss improved from 4.83603 to 4.63827, saving model to next_words.h5\n",
            "Epoch 7/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 4.4390\n",
            "\n",
            "Epoch 00007: loss improved from 4.63827 to 4.43897, saving model to next_words.h5\n",
            "Epoch 8/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 4.2460\n",
            "\n",
            "Epoch 00008: loss improved from 4.43897 to 4.24598, saving model to next_words.h5\n",
            "Epoch 9/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 4.0521\n",
            "\n",
            "Epoch 00009: loss improved from 4.24598 to 4.05209, saving model to next_words.h5\n",
            "Epoch 10/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 3.8508\n",
            "\n",
            "Epoch 00010: loss improved from 4.05209 to 3.85077, saving model to next_words.h5\n",
            "Epoch 11/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 3.6498\n",
            "\n",
            "Epoch 00011: loss improved from 3.85077 to 3.64976, saving model to next_words.h5\n",
            "Epoch 12/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 3.4436\n",
            "\n",
            "Epoch 00012: loss improved from 3.64976 to 3.44359, saving model to next_words.h5\n",
            "Epoch 13/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 3.2351\n",
            "\n",
            "Epoch 00013: loss improved from 3.44359 to 3.23513, saving model to next_words.h5\n",
            "Epoch 14/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 3.0253\n",
            "\n",
            "Epoch 00014: loss improved from 3.23513 to 3.02528, saving model to next_words.h5\n",
            "Epoch 15/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 2.8119\n",
            "\n",
            "Epoch 00015: loss improved from 3.02528 to 2.81192, saving model to next_words.h5\n",
            "Epoch 16/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 2.5897\n",
            "\n",
            "Epoch 00016: loss improved from 2.81192 to 2.58974, saving model to next_words.h5\n",
            "Epoch 17/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 2.3721\n",
            "\n",
            "Epoch 00017: loss improved from 2.58974 to 2.37210, saving model to next_words.h5\n",
            "Epoch 18/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 2.1531\n",
            "\n",
            "Epoch 00018: loss improved from 2.37210 to 2.15306, saving model to next_words.h5\n",
            "Epoch 19/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.9439\n",
            "\n",
            "Epoch 00019: loss improved from 2.15306 to 1.94393, saving model to next_words.h5\n",
            "Epoch 20/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 1.7422\n",
            "\n",
            "Epoch 00020: loss improved from 1.94393 to 1.74222, saving model to next_words.h5\n",
            "Epoch 21/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.5599\n",
            "\n",
            "Epoch 00021: loss improved from 1.74222 to 1.55992, saving model to next_words.h5\n",
            "Epoch 22/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.3994\n",
            "\n",
            "Epoch 00022: loss improved from 1.55992 to 1.39941, saving model to next_words.h5\n",
            "Epoch 23/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.2620\n",
            "\n",
            "Epoch 00023: loss improved from 1.39941 to 1.26204, saving model to next_words.h5\n",
            "Epoch 24/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.1464\n",
            "\n",
            "Epoch 00024: loss improved from 1.26204 to 1.14640, saving model to next_words.h5\n",
            "Epoch 25/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 1.0492\n",
            "\n",
            "Epoch 00025: loss improved from 1.14640 to 1.04921, saving model to next_words.h5\n",
            "Epoch 26/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.9733\n",
            "\n",
            "Epoch 00026: loss improved from 1.04921 to 0.97328, saving model to next_words.h5\n",
            "Epoch 27/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.9054\n",
            "\n",
            "Epoch 00027: loss improved from 0.97328 to 0.90537, saving model to next_words.h5\n",
            "Epoch 28/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.8547\n",
            "\n",
            "Epoch 00028: loss improved from 0.90537 to 0.85473, saving model to next_words.h5\n",
            "Epoch 29/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.8096\n",
            "\n",
            "Epoch 00029: loss improved from 0.85473 to 0.80957, saving model to next_words.h5\n",
            "Epoch 30/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.7745\n",
            "\n",
            "Epoch 00030: loss improved from 0.80957 to 0.77445, saving model to next_words.h5\n",
            "Epoch 31/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.7423\n",
            "\n",
            "Epoch 00031: loss improved from 0.77445 to 0.74230, saving model to next_words.h5\n",
            "Epoch 32/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.7175\n",
            "\n",
            "Epoch 00032: loss improved from 0.74230 to 0.71750, saving model to next_words.h5\n",
            "Epoch 33/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6969\n",
            "\n",
            "Epoch 00033: loss improved from 0.71750 to 0.69693, saving model to next_words.h5\n",
            "Epoch 34/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6715\n",
            "\n",
            "Epoch 00034: loss improved from 0.69693 to 0.67148, saving model to next_words.h5\n",
            "Epoch 35/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6574\n",
            "\n",
            "Epoch 00035: loss improved from 0.67148 to 0.65738, saving model to next_words.h5\n",
            "Epoch 36/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6427\n",
            "\n",
            "Epoch 00036: loss improved from 0.65738 to 0.64275, saving model to next_words.h5\n",
            "Epoch 37/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6259\n",
            "\n",
            "Epoch 00037: loss improved from 0.64275 to 0.62590, saving model to next_words.h5\n",
            "Epoch 38/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6145\n",
            "\n",
            "Epoch 00038: loss improved from 0.62590 to 0.61449, saving model to next_words.h5\n",
            "Epoch 39/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.6042\n",
            "\n",
            "Epoch 00039: loss improved from 0.61449 to 0.60418, saving model to next_words.h5\n",
            "Epoch 40/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5946\n",
            "\n",
            "Epoch 00040: loss improved from 0.60418 to 0.59463, saving model to next_words.h5\n",
            "Epoch 41/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5807\n",
            "\n",
            "Epoch 00041: loss improved from 0.59463 to 0.58068, saving model to next_words.h5\n",
            "Epoch 42/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5711\n",
            "\n",
            "Epoch 00042: loss improved from 0.58068 to 0.57108, saving model to next_words.h5\n",
            "Epoch 43/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5639\n",
            "\n",
            "Epoch 00043: loss improved from 0.57108 to 0.56392, saving model to next_words.h5\n",
            "Epoch 44/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5542\n",
            "\n",
            "Epoch 00044: loss improved from 0.56392 to 0.55424, saving model to next_words.h5\n",
            "Epoch 45/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5482\n",
            "\n",
            "Epoch 00045: loss improved from 0.55424 to 0.54818, saving model to next_words.h5\n",
            "Epoch 46/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5383\n",
            "\n",
            "Epoch 00046: loss improved from 0.54818 to 0.53834, saving model to next_words.h5\n",
            "Epoch 47/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5349\n",
            "\n",
            "Epoch 00047: loss improved from 0.53834 to 0.53493, saving model to next_words.h5\n",
            "Epoch 48/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5288\n",
            "\n",
            "Epoch 00048: loss improved from 0.53493 to 0.52876, saving model to next_words.h5\n",
            "Epoch 49/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5195\n",
            "\n",
            "Epoch 00049: loss improved from 0.52876 to 0.51948, saving model to next_words.h5\n",
            "Epoch 50/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5180\n",
            "\n",
            "Epoch 00050: loss improved from 0.51948 to 0.51797, saving model to next_words.h5\n",
            "Epoch 51/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5104\n",
            "\n",
            "Epoch 00051: loss improved from 0.51797 to 0.51039, saving model to next_words.h5\n",
            "Epoch 52/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.5051\n",
            "\n",
            "Epoch 00052: loss improved from 0.51039 to 0.50507, saving model to next_words.h5\n",
            "Epoch 53/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4987\n",
            "\n",
            "Epoch 00053: loss improved from 0.50507 to 0.49873, saving model to next_words.h5\n",
            "Epoch 54/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4974\n",
            "\n",
            "Epoch 00054: loss improved from 0.49873 to 0.49745, saving model to next_words.h5\n",
            "Epoch 55/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4908\n",
            "\n",
            "Epoch 00055: loss improved from 0.49745 to 0.49083, saving model to next_words.h5\n",
            "Epoch 56/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4861\n",
            "\n",
            "Epoch 00056: loss improved from 0.49083 to 0.48613, saving model to next_words.h5\n",
            "Epoch 57/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4826\n",
            "\n",
            "Epoch 00057: loss improved from 0.48613 to 0.48259, saving model to next_words.h5\n",
            "Epoch 58/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4804\n",
            "\n",
            "Epoch 00058: loss improved from 0.48259 to 0.48044, saving model to next_words.h5\n",
            "Epoch 59/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4711\n",
            "\n",
            "Epoch 00059: loss improved from 0.48044 to 0.47111, saving model to next_words.h5\n",
            "Epoch 60/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4707\n",
            "\n",
            "Epoch 00060: loss improved from 0.47111 to 0.47073, saving model to next_words.h5\n",
            "Epoch 61/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4662\n",
            "\n",
            "Epoch 00061: loss improved from 0.47073 to 0.46620, saving model to next_words.h5\n",
            "Epoch 62/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4713\n",
            "\n",
            "Epoch 00062: loss did not improve from 0.46620\n",
            "Epoch 63/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4584\n",
            "\n",
            "Epoch 00063: loss improved from 0.46620 to 0.45838, saving model to next_words.h5\n",
            "Epoch 64/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4590\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.45838\n",
            "Epoch 65/70\n",
            "1959/1959 [==============================] - 30s 16ms/step - loss: 0.4519\n",
            "\n",
            "Epoch 00065: loss improved from 0.45838 to 0.45192, saving model to next_words.h5\n",
            "Epoch 66/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4520\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.45192\n",
            "Epoch 67/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4509\n",
            "\n",
            "Epoch 00067: loss improved from 0.45192 to 0.45086, saving model to next_words.h5\n",
            "Epoch 68/70\n",
            "1959/1959 [==============================] - 31s 16ms/step - loss: 0.4506\n",
            "\n",
            "Epoch 00068: loss improved from 0.45086 to 0.45061, saving model to next_words.h5\n",
            "Epoch 69/70\n",
            "1959/1959 [==============================] - 31s 16ms/step - loss: 0.4400\n",
            "\n",
            "Epoch 00069: loss improved from 0.45061 to 0.44001, saving model to next_words.h5\n",
            "Epoch 70/70\n",
            "1959/1959 [==============================] - 30s 15ms/step - loss: 0.4417\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.44001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b6950cc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lrH_LIw4QDo"
      },
      "source": [
        "# Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnK4o4TA4UJ4"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPDbfiDp4b7J",
        "outputId": "6b2dd2fb-f7e9-4a8d-a0eb-f640a988a735"
      },
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your line: after the melancholy scene so lately\n",
            "['scene', 'so', 'lately']\n",
            "gone\n",
            "Enter your line: 0\n",
            "Execution completed.....\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}